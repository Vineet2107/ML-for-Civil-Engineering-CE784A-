{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled48.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/Vineet2107/ML-for-Civil-Engineering-CE784A-/blob/main/Untitled48.ipynb",
      "authorship_tag": "ABX9TyOQzN62ulAbJAOA42ZV60wE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineet2107/ML-for-Civil-Engineering-CE784A-/blob/main/Untitled48.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQyn8fR5E4Vu",
        "outputId": "4f65deb8-7728-4930-ba52-dfb23ddefe94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for glob\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement random (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for random\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting skimage\n",
            "  Downloading skimage-0.0.tar.gz (757 bytes)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/3b/ee/edbfa69ba7b7d9726e634bfbeefd04b5a1764e9e74867ec916113eeaf4a1/skimage-0.0.tar.gz#sha256=6c96a11d9deea68489c9b80b38fad1dcdab582c36d4fa093b99b24a3b30c38ec (from https://pypi.org/simple/skimage/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement skimage (from versions: 0.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for skimage\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install keras\n",
        "!pip install glob\n",
        "!pip install cv2\n",
        "!pip install random\n",
        "!pip install sklearn\n",
        "!pip install skimage\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0gTSYveF0SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import os\n",
        "\n",
        "def FrameCapture(path,folder):\n",
        "\tcap = cv2.VideoCapture(path)\n",
        "\tproperty_id = int(cv2.CAP_PROP_FRAME_COUNT) \n",
        "\tlength = int(cv2.VideoCapture.get(cap, property_id))\n",
        "\tcount = 0\n",
        "\tsuccess = 1\n",
        "\tcut = length-99\n",
        "\t_dir =  \"/content/drive/MyDrive/Trimmed_accident_videos/frames\"+folder\n",
        "\tif not os.path.exists(_dir):\n",
        "\t\tos.mkdir(_dir)\n",
        "\n",
        "\twhile success:\n",
        "\t\tsuccess, image = cap.read()\n",
        "\t\tif success and count >= cut :\n",
        "\t\t\tn = count-cut\n",
        "\t\t\tcv2.imwrite(dir+\"/frame%d.jpg\" % n, image) \n",
        "\t\tcount += 1\n",
        "\t\t\n",
        "\n",
        "\n",
        "temp_dir = \"/content/drive/MyDrive/Trimmed_accident_videos\"\n",
        "for video_file in os.listdir(temp_dir):\n",
        "\tpath = temp_dir+\"/\"+video_file\n",
        "\tFrameCapture(path,video_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "AB2AfvPNFU5D",
        "outputId": "529b5e93-c76d-4229-ea5e-4dd0cafd99e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f073314f772c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mFrameCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-f073314f772c>\u001b[0m in \u001b[0;36mFrameCapture\u001b[0;34m(path, folder)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcut\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/frame%d.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'builtin_function_or_method' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import the required libraries \n",
        "for image processing ,building the model\n",
        "and for plotting the graphs\n",
        "'''\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "import random\n",
        "import sklearn\n",
        "import skimage\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from keras.layers import LSTM\n",
        "from skimage import transform\n",
        "from keras.models import Model \n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.layers import Input,Dense,TimeDistributed\n",
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
        "\n",
        "'''\n",
        "initialisation of batch_size,num_classes and epochs\n",
        "'''\n",
        "batch_size = 15\n",
        "num_classes = 2\n",
        "epochs = 40\n",
        "\n",
        "#size of each extacted frame\n",
        "row_hidden = 128\n",
        "col_hidden = 128\n",
        "\n",
        "\n",
        "frame , row, col =(99,144,256)\n",
        "\n",
        "'''\n",
        "Loading all the Positive and negative according to the desired \n",
        "file path and the load_set preprocess the data in which each frame\n",
        "is extracted to a paricular size of (144,256)\n",
        "'''\n",
        "\n",
        "def load_set(img_path):\n",
        "  img = load_img(img_path)\n",
        "  tmp = skimage.color.rgb2gray(np.array(img))\n",
        "  tmp = transform.resize(tmp, (144, 256))\n",
        "  return tmp\n",
        "\n",
        "'''\n",
        "Loading all the Positive and negative according to the desired \n",
        "file path and the load_set preprocess the data in which each frame\n",
        "is extracted to a paricular size of (144,256) and is horizontally filpped\n",
        "'''\n",
        "\n",
        "def horizontal_flip(img_path):\n",
        "  img = load_img(img_path)\n",
        "  tmp = skimage.color.rgb2gray(np.array(img))\n",
        "  tmp = skimage.transform.resize(tmp, (144, 256))\n",
        "  tmp = np.array(tmp)\n",
        "  tmp = np.flip(tmp, axis = 1)\n",
        "  return tmp\n",
        "\n",
        "\n",
        "'''\n",
        "Loading all the Positive and negative files assigned to varaiable\n",
        "neg and pos respectively\n",
        "All files contains both the files paths\n",
        "'''\n",
        "pos = glob.glob( '99frames/*.mp4')\n",
        "neg = glob.glob( 'negative/*.mp4')\n",
        "all_files = np.concatenate((pos, neg[0:len(pos)]))\n",
        "\n",
        "#print(len(neg),len(pos))\n",
        "#print(all_files) \n",
        "\n",
        "\n",
        "'''\n",
        "label matrix is used to make one hot encoding ie [0 1] for\n",
        "positve data and [1 0] for negative data\n",
        "'''\n",
        "\n",
        "\n",
        "def label_matrivalues):\n",
        "\n",
        "  n_values = np.mavalues) + 1 \n",
        "  return np.eye(n_values)[values] \n",
        "\n",
        "labels = np.concatenate(([1]*len(pos), [0]*len(neg[0:len(pos)]))) \n",
        "labels = label_matrilabels) \n",
        "#print(len(labels)) \n",
        "\n",
        "\n",
        "def load_data1(path):\n",
        "\n",
        "  x = []\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "    img_path = path+\"/\"+files\n",
        "    if files !=(\"frame99.jpg\"):\n",
        "      img = load_set(img_path)\n",
        "    x.append(img)\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "def load_data3(path):\n",
        "  count = 0\n",
        "  x = []\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "    img_path = path+\"/\"+files\n",
        "    if count < 99:\n",
        "      count = count + 1\n",
        "      img = load_set(img_path)\n",
        "    x.append(img)\n",
        "  return x\n",
        "\n",
        "\n",
        "def load_data2(path): \n",
        "  x = []\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "    img_path = path+\"/\"+files\n",
        "    if files !=(\"frame99.jpg\") :\n",
        "      img = horizontal_flip(img_path)\n",
        "    x.append(img)\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "def load_data4(path): \n",
        "  x = []\n",
        "  count =0\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "    img_path = path+\"/\"+files\n",
        "    if count < 99 :\n",
        "      count = count +1\n",
        "      img = horizontal_flip(img_path)\n",
        "    x.append(img)\n",
        "  return x \n",
        "\n",
        "'''\n",
        "this function used to make dataset depending upon file name\n",
        "'''\n",
        "def make_dataset(rand):\n",
        "  seq1 = np.zeros((len(rand), 99, 144, 256)) \n",
        "  for i,fi in enumerate(rand): \n",
        "    print (i, fi)\n",
        "    if fi[9:11] == '00' :\n",
        "      t = load_data1(fi)\n",
        "    elif fi[9:13] == 'MVIH':\n",
        "      t = load_data3(fi)\n",
        "    elif fi[9:13] == 'MVI_': \n",
        "      t = load_data4(fi) \n",
        "    elif fi[9:11]=='11' :\n",
        "      t = load_data2(fi) \n",
        "\n",
        "    seq1[i] = t \n",
        "\n",
        "  return seq1\n",
        "\n",
        "'''\n",
        "make the x_test,x_train and validation data in ration of \n",
        "(60% 20% 20%)\n",
        "'''\n",
        "\n",
        "x_train, x_t1, y_train, y_t1 = train_test_split(all_files, labels, test_size=0.40, random_state=0) \n",
        "x_train = np.array(x_train); y_train = np.array(y_train) \n",
        "\n",
        "x_testA = np.array(x_t1[int(len(x_t1)/2):]); y_testA = np.array(y_t1[int(len(y_t1)/2):]) \n",
        "x_testA = make_dataset(x_testA)\n",
        "\n",
        "### valid set for model\n",
        "x_testB = np.array(x_t1[:int(len(x_t1)/2)]); y_testB = np.array(y_t1[:int(len(y_t1)/2)]) \n",
        "x_testB = make_dataset(x_testB)\n",
        "\n",
        "\n",
        "'''\n",
        "making the pipeline using keras\n",
        "using auto encoders(HRRN and LSTM)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "x =Input(shape=(frame, row, col))\n",
        "encoded_rows = TimeDistributed(LSTM(row_hidden))(x) \n",
        "encoded_columns =LSTM(col_hidden)(encoded_rows)\n",
        "\n",
        "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
        "\n",
        "model = Model(x, prediction)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "optimizer='NAdam', \n",
        "metrics=['accuracy']) \n",
        "model.summary()\n",
        "\n",
        "i=0; filepath='HRNN_pretrained_model.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "np.random.seed(18247)\n",
        "\n",
        "'''\n",
        "training on dataset as well as validation\n",
        "'''\n",
        "\n",
        "for i in range(0, epochs): \n",
        "  c = list(zip(x_train, y_train)) \n",
        "  random.shuffle(c) \n",
        "  x_shuff, y_shuff = zip(*c) \n",
        "  x_shuff = np.array(x_shuff); y_shuff=np.array(y_shuff) \n",
        "\n",
        "x_batch = [x_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] \n",
        "y_batch = [y_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] \n",
        "\n",
        "for j,xb in enumerate(x_batch): \n",
        "  xx = make_dataset(xb) \n",
        "  yy = y_batch[j] \n",
        "\n",
        "model.fit(xx, yy, \n",
        "batch_size=len(xx), \n",
        "epochs=3, \n",
        "validation_data=(x_testB, y_testB), \n",
        "callbacks=callbacks_list\n",
        ") \n",
        "\n",
        "loss = model.history['loss']\n",
        "val_loss = model.history['val_loss']\n",
        "epochs = range(epochs)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "evaluating model on test dataset\n",
        "'''\n",
        "scores = model.evaluate(x_testA, y_testA, verbose=0) \n",
        "print('Test loss:', scores[0]) \n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "y-KlVZW1G7O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Model \n",
        "from keras.layers import Input,Dense,TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img_filepath = \"/home/ritwik/Desktop/MINI PROJECT/\"\n",
        "pos = glob.glob(img_filepath + '99frames/*.mp4')\n",
        "neg = glob.glob(img_filepath + 'negative/*.mp4')\n",
        "all_files =  np.concatenate((pos, neg))\n",
        "print(len(neg),len(pos))\n",
        "print(all_files)       \n",
        "\n",
        "\n",
        "def label_matrix(values):\n",
        "  n_values = np.max(values) + 1    \n",
        "  return np.eye(n_values)[values] \n",
        "\n",
        "labels = np.concatenate(([1]*len(pos), [0]*len(neg[0:len(pos)])))  \n",
        "labels = label_matrix(labels)    \n",
        "print(len(labels))      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 15\n",
        "num_classes = 2\n",
        "epochs = 30\n",
        "\n",
        "row_hidden = 128\n",
        "col_hidden = 128\n",
        "\n",
        "\n",
        "frame , row, col =(99,144,256)\n",
        "\n",
        "x =Input(shape=(frame, row, col))\n",
        "encoded_rows = TimeDistributed(LSTM(row_hidden))(x) \n",
        "encoded_columns =LSTM(col_hidden)(encoded_rows)\n",
        "\n",
        "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
        "\n",
        "model = Model(x, prediction)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "\t\t\t\toptimizer='NAdam',               \n",
        "\t\t\t\tmetrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iBZksCDBG9Ct",
        "outputId": "872e245e-2e05-4df6-a8fa-85afc7b3f4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "[]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b2835908aba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b2835908aba6>\u001b[0m in \u001b[0;36mlabel_matrix\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlabel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2753\u001b[0m     \"\"\"\n\u001b[1;32m   2754\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2755\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ]
    }
  ]
}